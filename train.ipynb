{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "\n",
    "print(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random \n",
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def extract_content(json_obj):\n",
    "    messages = []\n",
    "    for edit in json_obj.get('edits', []):\n",
    "        content_msg = []\n",
    "        # Content 1 \n",
    "        content1 = edit.get('src', {}).get('text')\n",
    "        content1_path = edit.get('src', {}).get('path')\n",
    "        content1_lang = edit.get('src', {}).get('lang') \n",
    "\n",
    "        # Content 2 \n",
    "        content2 = edit.get('tgt', {}).get('text')\n",
    "        content2_path = edit.get('tgt', {}).get('path')\n",
    "        content2_lang = edit.get('tgt', {}).get('lang')\n",
    "        \n",
    "        if content1:\n",
    "            # \\nContent language: {content1_lang} \\\n",
    "            content1_format = f\"\"\"The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\n",
    "                                \\n\\nContent path: \"{content1_path}\"\n",
    "                                \\nINVALID CODE SNIPPET:\\n\"{content1.strip()}\" \"\"\"\n",
    "                                \n",
    "            content_msg.append({'content': content1_format, 'role': \"user\"})\n",
    "        if content2:\n",
    "            # \\nContent language: {content2_lang} \\\n",
    "            content2_format = f\"\"\"The typo identified in the code snippet is: \"{content2.strip()}\"\n",
    "                                \\n\\nContent path: \"{content2_path}\"\n",
    "                                \\nCORRECTED CODE SNIPPET:\\n\"{content2.strip()}\" \"\"\"\n",
    "\n",
    "            content_msg.append({'content': content2_format, 'role': \"assistant\", })\n",
    "\n",
    "            messages.append({\"messages\": content_msg})\n",
    "    return messages\n",
    "\n",
    "# Example usage\n",
    "file_path = 'data/typo.jsonl'\n",
    "all_messages = []\n",
    "\n",
    "for json_obj in read_jsonl(file_path):\n",
    "    messages = extract_content(json_obj)\n",
    "    all_messages.extend(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = all_messages[:10000]\n",
    "\n",
    "def write_jsonl(data, file_path):\n",
    "    ndjson_data = \"\\n\".join(json.dumps(item) for item in data)\n",
    "    with open(file_path, \"w\") as jsonl_file:\n",
    "        jsonl_file.write(ndjson_data)\n",
    "\n",
    "# Write the messages to a JSONL file\n",
    "messages_file_path = 'data/messages.jsonl'\n",
    "write_jsonl(all_messages, messages_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_messages\n",
    "data = data[:10000]\n",
    "\n",
    "# Split data\n",
    "train_ratio = 0.901\n",
    "eval_ratio = 0.04 \n",
    "test_ratio = 0.04\n",
    "\n",
    "train_size = int(len(data) * train_ratio)\n",
    "eval_size = int(len(data) * eval_ratio)\n",
    "\n",
    "train_data = data[:train_size]\n",
    "eval_data = data[train_size:train_size + eval_size]\n",
    "test_data = data[train_size + eval_size:]\n",
    "\n",
    "write_jsonl(train_data, 'data/training_file.jsonl')\n",
    "write_jsonl(eval_data, 'data/evaluation_file.jsonl')\n",
    "write_jsonl(test_data, 'data/test_file.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/default/le-bot/train.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://vscode-session-7z58h9iwyu3v6mlc18zqcwnuag.i.anyscaleuserdata.com/home/ray/default/le-bot/train.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m load_dotenv(\u001b[39m'\u001b[39m\u001b[39mconf/secrets.env\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-7z58h9iwyu3v6mlc18zqcwnuag.i.anyscaleuserdata.com/home/ray/default/le-bot/train.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m client \u001b[39m=\u001b[39m MistralClient(api_key\u001b[39m=\u001b[39mapi_key)\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-7z58h9iwyu3v6mlc18zqcwnuag.i.anyscaleuserdata.com/home/ray/default/le-bot/train.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/training_file.jsonl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv('conf/secrets.env')\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "with open(\"data/training_file.jsonl\", \"rb\") as f:\n",
    "    training_data = client.files.create(file=(\"training_file.jsonl\", f), purpose=\"fine-tune\")    \n",
    "\n",
    "with open(\"data/evaluation_file.jsonl\", \"rb\") as f:\n",
    "    evaluation_file = client.files.create(file=(\"evaluation_file.jsonl\", f), purpose=\"fine-tune\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='f750409c-3cb7-4de0-8ed9-5e57ecd28446', hyperparameters=TrainingParameters(training_steps=1, learning_rate=0.0001), fine_tuned_model=None, model='open-mistral-7b', status='QUEUED', job_type='FT', created_at=1719641600, modified_at=1719641600, training_files=['ce5440d3-f1e4-4c25-960a-40461f7d3d7f'], validation_files=['d50d315e-b2b7-409a-8fbc-07ed0cbee2b7'], object='job', integrations=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mistralai.models.jobs import TrainingParameters\n",
    "\n",
    "created_jobs = client.jobs.create(\n",
    "    model=\"open-mistral-7b\",\n",
    "    training_files=[training_data.id],\n",
    "    validation_files=[evaluation_file.id],\n",
    "    hyperparameters=TrainingParameters(\n",
    "        training_steps=1,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")\n",
    "created_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=[Job(id='f750409c-3cb7-4de0-8ed9-5e57ecd28446', hyperparameters=TrainingParameters(training_steps=1, learning_rate=0.0001), fine_tuned_model=None, model='open-mistral-7b', status='QUEUED', job_type='FT', created_at=1719641600, modified_at=1719641600, training_files=['ce5440d3-f1e4-4c25-960a-40461f7d3d7f'], validation_files=['d50d315e-b2b7-409a-8fbc-07ed0cbee2b7'], object='job', integrations=[]), Job(id='89dd3dee-630a-4c66-b6f9-c7eab654efa8', hyperparameters=TrainingParameters(training_steps=1, learning_rate=0.0001), fine_tuned_model=None, model='open-mistral-7b', status='RUNNING', job_type='FT', created_at=1719641554, modified_at=1719641554, training_files=['24022699-8f73-4a52-b486-c664c74112a6'], validation_files=['d0f6d296-96ee-43ac-bb0f-30670b3780cf'], object='job', integrations=[]), Job(id='a3ed164c-5b8f-4df0-aa39-63a4f324fdb6', hyperparameters=TrainingParameters(training_steps=1, learning_rate=0.0001), fine_tuned_model='ft:open-mistral-7b:b25ac4af:20240606:a3ed164c', model='open-mistral-7b', status='SUCCESS', job_type='FT', created_at=1717660544, modified_at=1717660581, training_files=['8854ca5b-8c8e-4541-85b8-3fcaf466058f'], validation_files=['aa6d80ef-5b8b-45a6-935d-915dd65e52a4'], object='job', integrations=[])] object='list'\n",
      "id='f750409c-3cb7-4de0-8ed9-5e57ecd28446' hyperparameters=TrainingParameters(training_steps=1, learning_rate=0.0001) fine_tuned_model=None model='open-mistral-7b' status='RUNNING' job_type='FT' created_at=1719641600 modified_at=1719641601 training_files=['ce5440d3-f1e4-4c25-960a-40461f7d3d7f'] validation_files=['d50d315e-b2b7-409a-8fbc-07ed0cbee2b7'] object='job' integrations=[] events=[Event(name='status-updated', data={'status': 'RUNNING'}, created_at=1719641601), Event(name='status-updated', data={'status': 'QUEUED'}, created_at=1719641600)] checkpoints=[] estimated_start_time=None\n"
     ]
    }
   ],
   "source": [
    "jobs = client.jobs.list()\n",
    "print(jobs)\n",
    "\n",
    "retrieved_jobs = client.jobs.retrieve(created_jobs.id)\n",
    "print(retrieved_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_job = client.jobs.retrieve(job_id=\"f750409c-3cb7-4de0-8ed9-5e57ecd28446\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "chat_response = client.chat(\n",
    "    model=retrieved_job.fine_tuned_model,\n",
    "    messages=[ChatMessage(role='user', content=f\"\"\"The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\n",
    "                                \\n\\nContent path: \"javascripts/db.js\"\n",
    "                                \\nINVALID CODE SNIPPET:\\n\"// Return a promise that either resolves with the most recent doducment\" \"\"\"\n",
    "                                )]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The typo in the code snippet is in the word \"doducment\". It should be \"document\". Here's the corrected version:\n",
      "\n",
      "\"// Return a promise that either resolves with the most recent document\"\n"
     ]
    }
   ],
   "source": [
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Evaluation method   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "test_evaluation_dataset = test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'content': 'The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\\n                                \\n\\nContent path: \"javascripts/db.js\"\\n                                \\nINVALID CODE SNIPPET:\\n\"// Return a promise that either resolves with the most recent doducment\" ',\n",
       "    'role': 'user'},\n",
       "   {'content': 'The typo identified in the code snippet is: \"// Return a promise that either resolves with the most recent docucment\"\\n                                \\n\\nContent path: \"javascripts/db.js\"\\n                                \\nCORRECTED CODE SNIPPET:\\n\"// Return a promise that either resolves with the most recent docucment\" ',\n",
       "    'role': 'assistant'}]}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluation_dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'content': 'The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\\n                                \\n\\nContent path: \"doc/models.md\"\\n                                \\nINVALID CODE SNIPPET:\\n\"`C(\\'name\\')` - a pipeline config option\" ',\n",
       "    'role': 'user'},\n",
       "   {'content': 'The typo identified in the code snippet is: \"- `C(\\'name\\')` - a pipeline config option\"\\n                                \\n\\nContent path: \"doc/models.md\"\\n                                \\nCORRECTED CODE SNIPPET:\\n\"- `C(\\'name\\')` - a pipeline config option\" ',\n",
       "    'role': 'assistant'}]}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "def chat_model(query):\n",
    "    query_formatted = query\n",
    "    context = \"You are a github expert in identifying mistakes, understanding user request and suggesting best coding practices.\"\n",
    "    \n",
    "    prompt_template = f\"\"\"\n",
    "                    ### CONTEXT ###\n",
    "                    {context}\n",
    "\n",
    "                    ### EXAMPLES ### \n",
    "                    The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\n",
    "                    \\n\\nContent path: \"doc/models.md\"\n",
    "                    \\nINVALID CODE SNIPPET:\\n\"`C(\\'name\\')` - a pipeline config option\" ',\n",
    "\n",
    "                    'The typo identified in the code snippet is: \"- `C(\\'name\\')` - a pipeline config option\"\\n\n",
    "                    \\n\\nContent path: \"doc/models.md\"\\n\n",
    "                    \\nCORRECTED CODE SNIPPET:\\n\"- `C(\\'name\\')` - a pipeline config option\" ',\n",
    "\n",
    "\n",
    "                    ### TASK ###\n",
    "                    {query_formatted}\n",
    "\n",
    "                    'The typo identified in the code snippet is:\n",
    "                    \\n\\nContent path:\n",
    "                    \\nCORRECTED CODE SNIPPET:\n",
    "\n",
    "                    ## INSTRUCTIONS ## \n",
    "                    Return the answer in json format. \n",
    "                    \"\"\"\n",
    "    \n",
    "    chat_response = client.chat(\n",
    "        model=retrieved_job.fine_tuned_model,\n",
    "        messages=[ChatMessage(role='user', \n",
    "                              content=prompt_template\n",
    "                                )])\n",
    "    \n",
    "    return chat_response, chat_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def chat_model_evaluator(llm1_query, llm1_answer, gold_truth):\n",
    "\n",
    "    llm1_context = \"You are a github expert in identifying mistakes, understanding user request and suggesting best coding practices.\"\n",
    "    \n",
    "    llm_evaluator_task = f\"\"\"\n",
    "                        ### TASK ###\n",
    "                        Evaluate the response from LLM1. Based on LLM1 CONTEXT, LLM1 TASK and LLM1 RESPONSE TO TASK in comparison to GOLD ANSWER,\n",
    "                        determine if LLM1 RESPONSE TO TASK is accurate and coherent. \n",
    "\n",
    "                        Rate the LLM1 RESPONSE TO TASK on how accurate and coherent it is, return a value between 0 and 1 in JSON FORMAT.\n",
    "                        Reference EXAMPLE RESPONSE to RATE THE ANSWER ACCURATELY AND NOT JUST 1.0. So responses can be 0.79 or 0.41...\n",
    "                        {{\"accurate_response\": String}}\n",
    "                        \"\"\"\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "                    ### LLM1 CONTEXT ###\n",
    "                    {llm1_context}\n",
    "\n",
    "                    ### LLM1 EXAMPLES ### \n",
    "                    The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\n",
    "                    \\n\\nContent path: \"doc/models.md\"\n",
    "                    \\nINVALID CODE SNIPPET:\\n\"`C(\\'name\\')` - a pipeline config option\" ',\n",
    "\n",
    "                    'The typo identified in the code snippet is: \"- `C(\\'name\\')` - a pipeline config option\"\\n\n",
    "                    \\n\\nContent path: \"doc/models.md\"\\n\n",
    "                    \\nCORRECTED CODE SNIPPET:\\n\"- `C(\\'name\\')` - a pipeline config option\" ',\n",
    "\n",
    "                    ### LLM1 TASK ###\n",
    "                    {llm1_query}\n",
    "                    \n",
    "\n",
    "                    ### LLM1 RESPONSE TO TASK ###\n",
    "                    {llm1_answer}\n",
    "\n",
    "                    ### GOLD ANSWER ###\n",
    "                    {gold_truth}\n",
    "\n",
    "                    ### EXAMPLE RESPONSE ###\n",
    "\n",
    "                    The following CODE SNIPPET contains a typo. Please identify the mistake but do not change the original structure:\n",
    "                    \\n\\nContent path: \"doc/models.md\"\n",
    "                    \\nINVALID CODE SNIPPET:\\n\"`C(\\'name\\')` - a pipeline config option\" ',\n",
    "\n",
    "                    ## COHERENT AND ACCURATE ANSWER ##\n",
    "                    The mistake in the code snippet is subtle but important. The backticks () are used for indicating code blocks or inline code in Markdown. However, in this case, the backticks are misplaced and should be surrounding the text 'C(\\'name\\')' instead of single quotes. Here's the corrected version: \n",
    "                    \\nContent path: \"doc/models.md\"\n",
    "                    \\nCORRECTED CODE SNIPPET: \"C('name')` - a pipeline config option\"\n",
    "\n",
    "                    accurate_response value would be between (0.7 to 1],\n",
    "\n",
    "                    ## SEMI-COHERENT AND SEMI-ACCURATE ANSWER##\n",
    "                    There seems to be an issue with the code snippet. The single quotes ('') are used for enclosing text or string values, but in this case, they seem to be misplaced. It might be better to use backticks (`) to indicate a code block or inline code. Here's a suggested correction:\n",
    "                    \\nContent path: \"doc/models.md\"\n",
    "                    \\nCORRECTED CODE SNIPPET: \"C('name') - a pipeline config option\"\n",
    "\n",
    "                    accurate_response value would be between [0.4 to 0.7)\n",
    "\n",
    "                    ## NON-COHERENT AND NON-ACCURATE ANSWER, accurate_response is rated 0.26 ##\n",
    "                    The code snippet looks a bit off. I think the single quotes (') are causing the issue. Maybe we should try using double quotes (\"\") instead? Here's a possible fix:\n",
    "                    \\nContent path: \"doc/models.md\"\n",
    "                    \\nCORRECTED CODE SNIPPET: \"\"C('name')\"\" - a pipeline config option\"\n",
    "\n",
    "                    accurate_response value would be between [0 to 0.4)\n",
    "\n",
    "\n",
    "                    ### TASK ###\n",
    "                    {llm_evaluator_task}\n",
    "\n",
    "                    \"\"\"\n",
    "    \n",
    "    model = \"open-mistral-7b\"\n",
    "    chat_response = client.chat(\n",
    "        model=model,\n",
    "        messages=[ChatMessage(role='user', \n",
    "                              content=prompt_template\n",
    "                                )])\n",
    "    \n",
    "    return chat_response, chat_response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses = []\n",
    "only_chat_responses = []\n",
    "full_response_evaluators = []\n",
    "only_chat_response_evaluators = []\n",
    "gold_truths = []\n",
    "for test_jsonl_dict in test_evaluation_dataset:\n",
    "    incorrect_test_content_query = test_jsonl_dict['messages'][0]['content']\n",
    "    correct_test_content_query = test_jsonl_dict['messages'][1]['content']\n",
    "\n",
    "    full_response, only_chat_response = chat_model(query=incorrect_test_content_query)\n",
    "    \n",
    "    full_response_evaluator, only_chat_response_evaluator = chat_model_evaluator(llm1_query=incorrect_test_content_query\n",
    "                                                                                 , llm1_answer=only_chat_response\n",
    "                                                                                 , gold_truth = correct_test_content_query)\n",
    "    full_responses.append(full_response)\n",
    "    gold_truths.append(correct_test_content_query)\n",
    "    only_chat_responses.append(only_chat_response)\n",
    "    full_response_evaluators.append(full_response_evaluator)\n",
    "    only_chat_response_evaluators.append(only_chat_response_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "response_evaluation_dataframe = pd.DataFrame({\n",
    "    \"llm1_full_response\":full_responses,\n",
    "    \"llm1_extracted_answers\":only_chat_responses,\n",
    "    \"gold_truth\": gold_truths,\n",
    "    \"evaluator_full_response\": full_response_evaluators,\n",
    "    \"evaluator_extracted_answers\" :only_chat_response_evaluator\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"accurate_response\": 0.82}\\n\\nThe LLM1 response to the task is accurate and coherent. The typo identified is the missing backtick before the text \\'C(\\'name\\')\\'. The corrected code snippet correctly uses the backtick to indicate a code block or inline code. The response is also well-structured, with clear identification of the typo and the corrected code snippet. Overall, the response accurately identifies the typo and provides a correct correction, earning it a high accuracy score.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_chat_response_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm1_full_response</th>\n",
       "      <th>llm1_extracted_answers</th>\n",
       "      <th>gold_truth</th>\n",
       "      <th>evaluator_full_response</th>\n",
       "      <th>evaluator_extracted_answers</th>\n",
       "      <th>accurate_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id='0e8ade0af62a4e4c8ced2d1bbafc5c93' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"javascripts/db.js\",\\n  \"...</td>\n",
       "      <td>The typo identified in the code snippet is: \"/...</td>\n",
       "      <td>id='f0b2c71d7fdf4051881ea9a8c6ee95eb' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id='82dd9dfca4c245ddbabe44b34b071496' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"javascripts/db.js\",\\n  \"...</td>\n",
       "      <td>The typo identified in the code snippet is: \"/...</td>\n",
       "      <td>id='6081c40ce6b7465a95600885484d183f' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id='855f1e20c3d249c29cbc0255d07fd320' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"routes/pop.js\",\\n  \"typo...</td>\n",
       "      <td>The typo identified in the code snippet is: \"/...</td>\n",
       "      <td>id='db0327709dc54dfebd1aaae8b9aaf20b' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id='1ea8f3e32157462fbdf5118a55cc5a22' object='...</td>\n",
       "      <td>{\\n  \"Content path\": \"README.md\",\\n  \"Invalid ...</td>\n",
       "      <td>The typo identified in the code snippet is: \"A...</td>\n",
       "      <td>id='03a922002cd14ba7a615096f0297d9e5' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id='7248a54b28104f53890fd673452b024a' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"contents.json\",\\n  \"typo...</td>\n",
       "      <td>The typo identified in the code snippet is: \"\"...</td>\n",
       "      <td>id='6b6c543f1b9a4c4bb5053183bf7a138e' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id='6e9be35487ac4360811e0b38f51a0b68' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"README.rst\",\\n  \"typo_id...</td>\n",
       "      <td>The typo identified in the code snippet is: \"L...</td>\n",
       "      <td>id='26bdad95e9fc45cd921cc9e5faa41256' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id='a9b2124470584d1bb5a0429499dbb000' object='...</td>\n",
       "      <td>{\\n  \"Content path\": \"README.rst\",\\n  \"Typo id...</td>\n",
       "      <td>The typo identified in the code snippet is: \"J...</td>\n",
       "      <td>id='8fdd13acc23746938e3a3f9d91ae826e' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id='75f49e7a6a99432c8d8b9da9105c4533' object='...</td>\n",
       "      <td>{\\n  \"Content path\": \"README.rst\",\\n  \"Invalid...</td>\n",
       "      <td>The typo identified in the code snippet is: \"-...</td>\n",
       "      <td>id='505689a378004f27973d1f7309815184' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id='75150175a54f4db2a42cea3d9e6fc273' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"FileProvider.podspec\",\\n...</td>\n",
       "      <td>The typo identified in the code snippet is: \"s...</td>\n",
       "      <td>id='e0abcda2b5fc49c79e2cbf654f140052' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id='20285af092f74ddda7547cf2e7100738' object='...</td>\n",
       "      <td>{\\n  \"content_path\": \"documentation/index.jade...</td>\n",
       "      <td>The typo identified in the code snippet is: \"p...</td>\n",
       "      <td>id='9b5914092a064faaaae330b733c481a7' object='...</td>\n",
       "      <td>{\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  llm1_full_response  \\\n",
       "0  id='0e8ade0af62a4e4c8ced2d1bbafc5c93' object='...   \n",
       "1  id='82dd9dfca4c245ddbabe44b34b071496' object='...   \n",
       "2  id='855f1e20c3d249c29cbc0255d07fd320' object='...   \n",
       "3  id='1ea8f3e32157462fbdf5118a55cc5a22' object='...   \n",
       "4  id='7248a54b28104f53890fd673452b024a' object='...   \n",
       "5  id='6e9be35487ac4360811e0b38f51a0b68' object='...   \n",
       "6  id='a9b2124470584d1bb5a0429499dbb000' object='...   \n",
       "7  id='75f49e7a6a99432c8d8b9da9105c4533' object='...   \n",
       "8  id='75150175a54f4db2a42cea3d9e6fc273' object='...   \n",
       "9  id='20285af092f74ddda7547cf2e7100738' object='...   \n",
       "\n",
       "                              llm1_extracted_answers  \\\n",
       "0  {\\n  \"content_path\": \"javascripts/db.js\",\\n  \"...   \n",
       "1  {\\n  \"content_path\": \"javascripts/db.js\",\\n  \"...   \n",
       "2  {\\n  \"content_path\": \"routes/pop.js\",\\n  \"typo...   \n",
       "3  {\\n  \"Content path\": \"README.md\",\\n  \"Invalid ...   \n",
       "4  {\\n  \"content_path\": \"contents.json\",\\n  \"typo...   \n",
       "5  {\\n  \"content_path\": \"README.rst\",\\n  \"typo_id...   \n",
       "6  {\\n  \"Content path\": \"README.rst\",\\n  \"Typo id...   \n",
       "7  {\\n  \"Content path\": \"README.rst\",\\n  \"Invalid...   \n",
       "8  {\\n  \"content_path\": \"FileProvider.podspec\",\\n...   \n",
       "9  {\\n  \"content_path\": \"documentation/index.jade...   \n",
       "\n",
       "                                          gold_truth  \\\n",
       "0  The typo identified in the code snippet is: \"/...   \n",
       "1  The typo identified in the code snippet is: \"/...   \n",
       "2  The typo identified in the code snippet is: \"/...   \n",
       "3  The typo identified in the code snippet is: \"A...   \n",
       "4  The typo identified in the code snippet is: \"\"...   \n",
       "5  The typo identified in the code snippet is: \"L...   \n",
       "6  The typo identified in the code snippet is: \"J...   \n",
       "7  The typo identified in the code snippet is: \"-...   \n",
       "8  The typo identified in the code snippet is: \"s...   \n",
       "9  The typo identified in the code snippet is: \"p...   \n",
       "\n",
       "                             evaluator_full_response  \\\n",
       "0  id='f0b2c71d7fdf4051881ea9a8c6ee95eb' object='...   \n",
       "1  id='6081c40ce6b7465a95600885484d183f' object='...   \n",
       "2  id='db0327709dc54dfebd1aaae8b9aaf20b' object='...   \n",
       "3  id='03a922002cd14ba7a615096f0297d9e5' object='...   \n",
       "4  id='6b6c543f1b9a4c4bb5053183bf7a138e' object='...   \n",
       "5  id='26bdad95e9fc45cd921cc9e5faa41256' object='...   \n",
       "6  id='8fdd13acc23746938e3a3f9d91ae826e' object='...   \n",
       "7  id='505689a378004f27973d1f7309815184' object='...   \n",
       "8  id='e0abcda2b5fc49c79e2cbf654f140052' object='...   \n",
       "9  id='9b5914092a064faaaae330b733c481a7' object='...   \n",
       "\n",
       "                         evaluator_extracted_answers  accurate_class  \n",
       "0  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "1  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "2  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "3  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "4  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "5  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "6  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "7  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "8  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  \n",
       "9  {\"accurate_response\": 0.82}\\n\\nThe LLM1 respon...            0.82  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_accurate_response(input_string):\n",
    "    try:\n",
    "        # Extract the JSON part of the string\n",
    "        json_part = input_string.split('\\n\\n')[0]\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(json_part)\n",
    "        # Extract and return the accurate response\n",
    "        return data.get(\"accurate_response\")\n",
    "    except (json.JSONDecodeError, IndexError):\n",
    "        return None\n",
    "\n",
    "response_evaluation_dataframe['accurate_class'] = response_evaluation_dataframe['evaluator_extracted_answers'].apply(lambda x: extract_accurate_response(x))\n",
    "response_evaluation_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_evaluation_dataframe['accurate_class'] = response_evaluation_dataframe['accurate_class'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy of Mistral Ability to reply user based on coherent and accurate changes is 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy of Mistral Ability to reply user based on coherent and accurate changes is\", sum(response_evaluation_dataframe['accurate_class'])/len(response_evaluation_dataframe['accurate_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion & Learning Points \n",
    "\n",
    "\n",
    "\n",
    "#### Fine Tunning\n",
    "\n",
    "\n",
    "#### Evaluation \n",
    "- Model evaluation if not done well at the start is expensive and difficult to reevaluate. \n",
    "- Model ability to generate response that is coherent with semantic meaning can be evaluated faster by another LLM rather than with human evaluation if time is of an essence. The ability for the model to improve this evaluation process can be better evaluated if we provide a few shot example of what constitute as coherent , semi coherent and not coherent. - but the ability for the model to generate a range of values without a marking criteria is not possible. \n",
    "-  more improvements can be made to the prompt to break down the problem like a math issue; providing a rubric for marking along with COT prompting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
